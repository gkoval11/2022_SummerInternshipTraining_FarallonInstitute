{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 - Example: Satellite Data \n",
    "###  Days with sea surface temperature above a threshold\n",
    "\n",
    "In this chapter we exemplify the use of Sea Surface Temperature (SST) data in the cloud. \n",
    "\n",
    "This example analyzes a time series from an area of the ocean or a point. If an area, it averages SST values into a single value. Then it analyze the time series to assess when SST is above a given threshold. This could be used to study marine heatwaves, or use a SST threshold relevant to a marine species of interest.\n",
    "\n",
    "<span style=\"font-size:larger;\">__You must have the Zarr package installed as well__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter('ignore') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "#import fsspec # these libraries help reading cloud data\n",
    "#import dask\n",
    "#from dask.distributed import performance_report, Client, progress\n",
    "import datetime as dt\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from calendar import month_abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "\n",
    "# select either a range of lat/lon or a point. \n",
    "# If a point, set both entries to the same value\n",
    "latr = [20, 70] # make sure lat1 < lat2 since no test is done below to simplify the code\n",
    "lonr = [-140, -110] # lon1 < lon2, range -180:180. resolution daily 1km!\n",
    "\n",
    "# time range. data range available: 2002-06-01 to 2020-01-20. [start with a short period]\n",
    "dater = ['2018-01-01','2018-12-31'] # dates on the format 'YYYY-MM-DD' as string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## We are going to use the Multi-Scale Ultra High Resolution (MUR) Sea Surface Temperature (SST) data set\n",
    "### This dataset is stored the Amazon (AWS) Cloud. For more info and links to the data detail and examples, see: https://registry.opendata.aws/mur/\n",
    "\n",
    "This dataset is stored in `zarr` format, which is an optimized format for the large datasets and the cloud. It is not stored as one 'image' at a time or a gigantic netcdf file, but in 'chunks', so it is perfect for extracting time series.\n",
    "\n",
    "First, we open the dataset and explore it, but we are not downloading anything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first determine the file name using, in the format:\n",
    "# the s3 bucket [mur-sst], and the region [us-west-2], and the folder if applicable [zarr-v1] \n",
    "file_location = 'https://mur-sst.s3.us-west-2.amazonaws.com/zarr-v1'\n",
    "\n",
    "ds_sst = xr.open_zarr(file_location,consolidated=True) # open a zarr file using xarray\n",
    "# it is similar to open_dataset but it only reads the metadata\n",
    "\n",
    "ds_sst # we can treat it as a dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we know what the file contains, we select our data (region and time), operate on it if needed (if a region, average), and download only the selected data \n",
    "It takes a while given the high resolution of the data. So, be patient.... and if you're only testing, might want to choose a small region and a short time period first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide if a point or a region was given.\n",
    "if (latr[0]==latr[1]) | (lonr[0]==lonr[1]): # if we give it only one point\n",
    "    sst = ds_sst['analysed_sst'].sel(time = slice(dater[0],dater[1]),\n",
    "                                            lat  = latr[0], \n",
    "                                            lon  = lonr[0]\n",
    "                                           ).load()\n",
    "else: # if we give it an area, it extract the area and average SST over the area and returns a time series of SST\n",
    "    sst = ds_sst['analysed_sst'].sel(time = slice(dater[0],dater[1]),\n",
    "                                            lat  = slice(latr[0], latr[1]), \n",
    "                                            lon  = slice(lonr[0], lonr[1])\n",
    "                                           ).mean(dim={'time'}, skipna=True, keep_attrs=True).load() # skip 'not a number' (NaN) values and keep attributes\n",
    "\n",
    "sst = sst-273.15 # transform units from Kelvin to  Celsius\n",
    "sst.attrs['units']='deg C' # update units in metadata\n",
    "sst.to_netcdf('data/sst_example.nc') # saving the data, incase we want to come back to analyze the same data, but don't want to acquire it again from the cloud.\n",
    "sst # take a peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### *Execute the next cell only if your reading the data from a file - either no access to cloud, or not want to keep reading from it. Skip otherwise. (No problem if you executed it by mistake).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = xr.open_dataset('data/sst_example.nc') \n",
    "sst.close()\n",
    "sst = sst.analysed_sst # select only one variable\n",
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define latitude and longitude boundaries\n",
    "latr = [min(sst['lat']), max(sst['lat'])] \n",
    "lonr = [max(sst['lon']), min(sst['lon'])] \n",
    "\n",
    "# Select a region of our data, giving it a margin\n",
    "margin = 0\n",
    "region = np.array([[latr[0]-margin,latr[1]+margin],[lonr[0]+margin,lonr[1]-margin]]) \n",
    "\n",
    "#add state outlines\n",
    "states_provinces = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lines',\n",
    "        scale='50m',\n",
    "        facecolor='none')\n",
    "\n",
    "# Create and set the figure context\n",
    "fig = plt.figure(figsize=(16,10), dpi = 72) \n",
    "ax = plt.axes(projection=ccrs.PlateCarree()) \n",
    "ax.coastlines(resolution='50m',linewidth=1,color='black') \n",
    "ax.add_feature(cfeature.LAND, color='grey', alpha=0.3)\n",
    "ax.add_feature(states_provinces, linewidth = 0.5)\n",
    "ax.add_feature(cfeature.BORDERS, color = 'black')\n",
    "ax.set_extent([region[1,0],region[1,1],region[0,0],region[0,1]],crs=ccrs.PlateCarree()) \n",
    "ax.set_xticks(np.round([*np.arange(region[1,1],region[1,0]+1,5)][::-1],0), crs=ccrs.PlateCarree()) \n",
    "ax.set_yticks(np.round([*np.arange(np.floor(region[0,0]),region[0,1]+1,10)],1), crs=ccrs.PlateCarree()) \n",
    "ax.xaxis.set_major_formatter(LongitudeFormatter(zero_direction_label=True))\n",
    "ax.yaxis.set_major_formatter(LatitudeFormatter())\n",
    "ax.gridlines(linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "# Plot track data, color by temperature\n",
    "sst.plot(transform=ccrs.PlateCarree(),cbar_kwargs={'label': 'Temperature [deg C]'}, vmin = 0, cmap = \"RdBu_r\")\n",
    "plt.title('Averaged Temperature Values (2018)', fontdict = {'fontsize' : 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "For the cloud and data in the cloud, see resources listed in Chapter 5.\n",
    "\n",
    "### Resources specifically for this chapter:\n",
    "\n",
    "- [MUR SST Data](https://registry.opendata.aws/mur/). SST data in the cloud, with references the official datta website, examples and other resources.\n",
    "\n",
    "- [Pangeo OSM2020 Tutorial](https://github.com/pangeo-gallery/osm2020tutorial). This is a very good tutorial for ocean application and cloud computing. Plenty of examples. Many of the commands here are from this tutorial.\n",
    "\n",
    "### About MHW\n",
    "\n",
    "- [Marine heatwaves](http://www.marineheatwaves.org/all-about-mhws.html). A good place to begin to get info about the subject.\n",
    "\n",
    "- [Marine heatwaves code](https://github.com/ecjoliver/marineHeatWaves). Marine heatwaves code from E. Oliver.\n",
    "\n",
    "### If you want to learn more:\n",
    "\n",
    "- [Methods for accessing a AWS bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-bucket-intro.html). Bucket is the name of the cloud storage object. S3 stands for Amazon's Simple Storage Service.\n",
    "\n",
    "- [hvplot site](https://hvplot.holoviz.org/index.html). Plotting tool used here.\n",
    "\n",
    "- [zarr](https://zarr.readthedocs.io/en/stable/). Learn more about this big data storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
